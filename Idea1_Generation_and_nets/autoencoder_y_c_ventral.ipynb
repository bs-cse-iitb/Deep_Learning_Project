{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "536791cb",
   "metadata": {},
   "source": [
    "# FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4b212c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_size(model):\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    total_size = sum(p.element_size() * p.numel() for p in model.parameters())\n",
    "    # SIZE in GB\n",
    "    print(f\"TOTAL PARAMS : {total_params}\")\n",
    "    print(f\"MODEL SIZE : {total_size/(1024**3)} GB\")\n",
    "\n",
    "    \n",
    "def evaluate_model(model, loader, criterion):\n",
    "    \n",
    "    model.eval()\n",
    "    total_loss=0\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "\n",
    "            # Your training code here\n",
    "            batch = batch[0].to(device)  # Move data to the device if using GPU\n",
    "            outputs = model(batch)\n",
    "\n",
    "            recon_loss = criterion(outputs, batch).item()*len(batch)\n",
    "#             regularization_loss = model.calculate_regularization_loss()\n",
    "#             loss = recon_loss + regularization_loss\n",
    "\n",
    "            #train_loss_liss.append(round(loss.item(),6))\n",
    "            total_loss += round(recon_loss,6)\n",
    "        \n",
    "    total_loss = total_loss/len(loader.dataset)\n",
    "\n",
    "    model.train()\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1a86b8",
   "metadata": {},
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca72d4d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aditya/anaconda3/envs/ldm/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "\n",
    "# !nvidia-smi\n",
    "import argparse, os\n",
    "import numpy as np\n",
    "# from himalaya.backend import set_backend\n",
    "# from himalaya.ridge import RidgeCV\n",
    "# from himalaya.scoring import correlation_score\n",
    "# from sklearn.pipeline import make_pipeline\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# import time\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecbeff0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# python ridge.py --target c --roi ventral --subject subj01\n",
    "# python ridge.py --target init_latent --roi early --subject subj01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c172705f",
   "metadata": {},
   "source": [
    "# SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05dee7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'c'\n",
    "roi = 'ventral'\n",
    "subject = 'subj01'\n",
    "# backend = set_backend(\"numpy\", on_error=\"warn\")\n",
    "\n",
    "mridir = f'../../mrifeat/{subject}/'\n",
    "featdir = '../../nsdfeat/subjfeat/'\n",
    "savedir = f'../..//decoded_net/{subject}/'\n",
    "os.makedirs(savedir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00ee62a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "X_te = []\n",
    "\n",
    "for croi in [roi]:\n",
    "    if 'conv' in target: # We use averaged features for GAN due to large number of dimension of features\n",
    "        cX = np.load(f'{mridir}/{subject}_{croi}_betas_ave_tr.npy').astype(\"float32\")\n",
    "    else:\n",
    "        cX = np.load(f'{mridir}/{subject}_{croi}_betas_tr.npy').astype(\"float32\")\n",
    "    \n",
    "    cX_te = np.load(f'{mridir}/{subject}_{croi}_betas_ave_te.npy').astype(\"float32\")\n",
    "    \n",
    "    X.append(cX)\n",
    "    X_te.append(cX_te)\n",
    "\n",
    "X = np.hstack(X)\n",
    "X_te = np.hstack(X_te)\n",
    "\n",
    "\n",
    "Y = np.load(f'{featdir}/{subject}_each_{target}_tr.npy').astype(\"float32\").reshape([24980,-1])\n",
    "Y_te = np.load(f'{featdir}/{subject}_ave_{target}_te.npy').astype(\"float32\").reshape([X_te.shape[0],-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75aafb3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now making decoding model for... subj01:  ventral, c\n",
      "X (24980, 7604), Y (24980, 59136), X_te (982, 7604), Y_te (982, 59136)\n"
     ]
    }
   ],
   "source": [
    "print(f'Now making decoding model for... {subject}:  {roi}, {target}')\n",
    "print(f'X {X.shape}, Y {Y.shape}, X_te {X_te.shape}, Y_te {Y_te.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71f9c17",
   "metadata": {},
   "source": [
    "______\n",
    "_____"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be59933",
   "metadata": {},
   "source": [
    "## Subset small data : For Experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d014d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_samples = 500\n",
    "# X_train = X[:num_samples, :].copy()\n",
    "# Y_train = Y[:num_samples, :].copy()\n",
    "# X_test = X_te[:num_samples//5, :].copy()\n",
    "# Y_test = Y_te[:num_samples//5, :].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f74a2cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e8c49dcc",
   "metadata": {},
   "source": [
    "_______\n",
    "_______"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4df8e9",
   "metadata": {},
   "source": [
    "# DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e9903a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# # Initialize the StandardScaler\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "# # Fit the scaler on your data and transform it\n",
    "# Y_total = scaler.fit_transform(Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38bed5c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((24980, 59136), -0.37102437, 0.59869695, 33.0542, -28.098944)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_total = Y\n",
    "Y_total.shape, Y_total[:,2000].mean(), Y_total[:,2000].std(), Y_total.max(), Y_total.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "078b4fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "Y_train, Y_val = train_test_split(Y_total, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e78daa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data to PyTorch tensors\n",
    "Y_train_tensor = torch.tensor(Y_train, dtype=torch.float16)\n",
    "train_dataset = TensorDataset(Y_train_tensor)\n",
    "\n",
    "Y_val_tensor = torch.tensor(Y_val, dtype=torch.float16)\n",
    "val_dataset = TensorDataset(Y_val_tensor)\n",
    "\n",
    "# Create a DataLoader\n",
    "batch_size = 64  # Adjust as needed\n",
    "train_data_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_data_loader = DataLoader(val_dataset, batch_size=batch_size , shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "75df3b97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((19984, 59136), (4996, 59136))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape, Y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa994089",
   "metadata": {},
   "outputs": [],
   "source": [
    "del Y_train\n",
    "del Y_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69c03f6",
   "metadata": {},
   "source": [
    "# MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4cf614b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a more complex autoencoder model\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_size, encoding_size, weight_decay=1e-4):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_size, 2500),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2500, encoding_size)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(encoding_size, 2500),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2500, input_size)\n",
    "        )\n",
    "        \n",
    "        # Add L2 regularization to the linear layers\n",
    "        self.regularization = nn.MSELoss(reduction='sum')\n",
    "        self.weight_decay = weight_decay\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "    \n",
    "    def calculate_regularization_loss(self):\n",
    "        reg_loss = 0\n",
    "        for param in self.parameters():\n",
    "            reg_loss += self.regularization(param, torch.zeros_like(param))\n",
    "        return self.weight_decay * reg_loss\n",
    "        #return 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3a185c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f1490c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the input and encoding dimensions\n",
    "input_size = Y_train_tensor.shape[1]  # 59136\n",
    "encoding_size = 1000  # Adjust the encoding size as needed\n",
    "#encoding_size = 512  # Adjust the encoding size as needed\n",
    "\n",
    "\n",
    "# Create the autoencoder model\n",
    "model = Autoencoder(input_size, encoding_size)\n",
    "model = model.half()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5294c020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL PARAMS : 300745136\n",
      "MODEL SIZE : 0.5601814687252045 GB\n"
     ]
    }
   ],
   "source": [
    "get_model_size(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "94765ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cuda.empty_cache()\n",
    "# !nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "66851e8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Autoencoder(\n",
       "  (encoder): Sequential(\n",
       "    (0): Linear(in_features=59136, out_features=2500, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=2500, out_features=1000, bias=True)\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): Linear(in_features=1000, out_features=2500, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=2500, out_features=59136, bias=True)\n",
       "  )\n",
       "  (regularization): MSELoss()\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d5dddc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cuda.empty_cache()\n",
    "# !nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a89135d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8172565",
   "metadata": {},
   "source": [
    "# TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d8fb52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1 COMPLETED | TRAIN LOSS :: 0.41766929168334666| VAL LOSS :: 0.41851586729383505\n",
      "EPOCH 2 COMPLETED | TRAIN LOSS :: 0.3615413815552442| VAL LOSS :: 0.3632959101281025\n",
      "EPOCH 3 COMPLETED | TRAIN LOSS :: 0.32283287565052043| VAL LOSS :: 0.3251220116092874\n",
      "EPOCH 4 COMPLETED | TRAIN LOSS :: 0.29149765122097676| VAL LOSS :: 0.29370078102481983\n",
      "EPOCH 5 COMPLETED | TRAIN LOSS :: 0.26630151776421135| VAL LOSS :: 0.26829041353082467\n",
      "EPOCH 6 COMPLETED | TRAIN LOSS :: 0.24567798789031225| VAL LOSS :: 0.24746584387510007\n",
      "EPOCH 7 COMPLETED | TRAIN LOSS :: 0.22831468289631698| VAL LOSS :: 0.22988312550040035\n",
      "EPOCH 8 COMPLETED | TRAIN LOSS :: 0.2135922610588472| VAL LOSS :: 0.21507088430744595\n",
      "EPOCH 9 COMPLETED | TRAIN LOSS :: 0.2011265261208967| VAL LOSS :: 0.20242473298638913\n",
      "EPOCH 10 COMPLETED | TRAIN LOSS :: 0.19052292589071262| VAL LOSS :: 0.19176825780624496\n",
      "EPOCH 11 COMPLETED | TRAIN LOSS :: 0.18147134882906318| VAL LOSS :: 0.18260975900720575\n",
      "EPOCH 12 COMPLETED | TRAIN LOSS :: 0.17355573869095267| VAL LOSS :: 0.17472405584467576\n",
      "EPOCH 13 COMPLETED | TRAIN LOSS :: 0.1666914584667734| VAL LOSS :: 0.16780651060848673\n",
      "EPOCH 14 COMPLETED | TRAIN LOSS :: 0.16015752051641313| VAL LOSS :: 0.16131557586068856\n",
      "EPOCH 15 COMPLETED | TRAIN LOSS :: 0.15436685258206564| VAL LOSS :: 0.15545492934347474\n",
      "EPOCH 16 COMPLETED | TRAIN LOSS :: 0.14913610563450758| VAL LOSS :: 0.15033130044035228\n",
      "EPOCH 17 COMPLETED | TRAIN LOSS :: 0.144441334317454| VAL LOSS :: 0.14562616933546838\n",
      "EPOCH 18 COMPLETED | TRAIN LOSS :: 0.14038721206965568| VAL LOSS :: 0.14157302381905526\n",
      "EPOCH 19 COMPLETED | TRAIN LOSS :: 0.13702446257005607| VAL LOSS :: 0.13825181144915932\n",
      "EPOCH 20 COMPLETED | TRAIN LOSS :: 0.13390956870496393| VAL LOSS :: 0.13512362630104086\n",
      "EPOCH 21 COMPLETED | TRAIN LOSS :: 0.13123125395316249| VAL LOSS :: 0.13247052822257807\n",
      "EPOCH 22 COMPLETED | TRAIN LOSS :: 0.1283842498999199| VAL LOSS :: 0.1296175616493194\n",
      "EPOCH 23 COMPLETED | TRAIN LOSS :: 0.12624709112289823| VAL LOSS :: 0.127479229783827\n",
      "EPOCH 24 COMPLETED | TRAIN LOSS :: 0.12410348238590876| VAL LOSS :: 0.12533757506004803\n",
      "EPOCH 25 COMPLETED | TRAIN LOSS :: 0.12215768679943954| VAL LOSS :: 0.1233823973178543\n",
      "EPOCH 26 COMPLETED | TRAIN LOSS :: 0.12029799614691762| VAL LOSS :: 0.12153409287429942\n",
      "EPOCH 27 COMPLETED | TRAIN LOSS :: 0.1185440539931946| VAL LOSS :: 0.11976333987189751\n",
      "EPOCH 28 COMPLETED | TRAIN LOSS :: 0.11695269295436354| VAL LOSS :: 0.11817647397918335\n",
      "EPOCH 29 COMPLETED | TRAIN LOSS :: 0.11558724539631704| VAL LOSS :: 0.11686922778222578\n",
      "EPOCH 30 COMPLETED | TRAIN LOSS :: 0.11421730154123295| VAL LOSS :: 0.11545139491593279\n",
      "EPOCH 31 COMPLETED | TRAIN LOSS :: 0.11315180074059239| VAL LOSS :: 0.11436370736589274\n",
      "EPOCH 32 COMPLETED | TRAIN LOSS :: 0.11204246612289834| VAL LOSS :: 0.11326932646116894\n",
      "EPOCH 33 COMPLETED | TRAIN LOSS :: 0.11100951040832664| VAL LOSS :: 0.11219312409927944\n",
      "EPOCH 34 COMPLETED | TRAIN LOSS :: 0.11014925230184143| VAL LOSS :: 0.1113986409127302\n",
      "EPOCH 35 COMPLETED | TRAIN LOSS :: 0.10901773148518824| VAL LOSS :: 0.11022831925540433\n",
      "EPOCH 36 COMPLETED | TRAIN LOSS :: 0.10851957896317052| VAL LOSS :: 0.10977986429143312\n",
      "EPOCH 37 COMPLETED | TRAIN LOSS :: 0.10763899204363483| VAL LOSS :: 0.1088837868294636\n",
      "EPOCH 38 COMPLETED | TRAIN LOSS :: 0.10700924034227377| VAL LOSS :: 0.10823834807846279\n",
      "EPOCH 39 COMPLETED | TRAIN LOSS :: 0.1062623046437149| VAL LOSS :: 0.10748335048038425\n",
      "EPOCH 40 COMPLETED | TRAIN LOSS :: 0.1056189190352282| VAL LOSS :: 0.10681245156124902\n",
      "EPOCH 41 COMPLETED | TRAIN LOSS :: 0.10486377336869489| VAL LOSS :: 0.10608017654123297\n",
      "EPOCH 42 COMPLETED | TRAIN LOSS :: 0.10431206295036036| VAL LOSS :: 0.1055092129703763\n",
      "EPOCH 43 COMPLETED | TRAIN LOSS :: 0.10366041888510803| VAL LOSS :: 0.1049017433947158\n",
      "EPOCH 44 COMPLETED | TRAIN LOSS :: 0.10324118654923928| VAL LOSS :: 0.10447303242594075\n",
      "EPOCH 45 COMPLETED | TRAIN LOSS :: 0.10258954253402722| VAL LOSS :: 0.10382500320256204\n",
      "EPOCH 46 COMPLETED | TRAIN LOSS :: 0.10208831184947968| VAL LOSS :: 0.10332416253002398\n",
      "EPOCH 47 COMPLETED | TRAIN LOSS :: 0.10137915037029624| VAL LOSS :: 0.10261607726180944\n",
      "EPOCH 48 COMPLETED | TRAIN LOSS :: 0.10108184192353885| VAL LOSS :: 0.10229580124099283\n",
      "EPOCH 49 COMPLETED | TRAIN LOSS :: 0.10059209512610089| VAL LOSS :: 0.1018187598078463\n",
      "EPOCH 50 COMPLETED | TRAIN LOSS :: 0.10015776356084873| VAL LOSS :: 0.10135476521216974\n",
      "EPOCH 51 COMPLETED | TRAIN LOSS :: 0.09982937469975976| VAL LOSS :: 0.10105086008807042\n",
      "EPOCH 52 COMPLETED | TRAIN LOSS :: 0.09940882375900713| VAL LOSS :: 0.10067238430744602\n",
      "EPOCH 53 COMPLETED | TRAIN LOSS :: 0.09912769080264212| VAL LOSS :: 0.10034482686148918\n",
      "EPOCH 54 COMPLETED | TRAIN LOSS :: 0.09898841943554844| VAL LOSS :: 0.10020648418734986\n",
      "EPOCH 55 COMPLETED | TRAIN LOSS :: 0.09868148433747| VAL LOSS :: 0.09994045136108888\n",
      "EPOCH 56 COMPLETED | TRAIN LOSS :: 0.09816432225780618| VAL LOSS :: 0.09938473218574861\n",
      "EPOCH 57 COMPLETED | TRAIN LOSS :: 0.09787326931545234| VAL LOSS :: 0.09910917033626902\n",
      "EPOCH 58 COMPLETED | TRAIN LOSS :: 0.0976612345876701| VAL LOSS :: 0.09887079523618893\n",
      "EPOCH 59 COMPLETED | TRAIN LOSS :: 0.0975068627401922| VAL LOSS :: 0.09872785888710968\n",
      "EPOCH 60 COMPLETED | TRAIN LOSS :: 0.09714382866293035| VAL LOSS :: 0.09834127001601281\n",
      "EPOCH 61 COMPLETED | TRAIN LOSS :: 0.09688835038030424| VAL LOSS :: 0.09813612670136108\n",
      "EPOCH 62 COMPLETED | TRAIN LOSS :: 0.09669752411929548| VAL LOSS :: 0.09792438450760607\n",
      "EPOCH 63 COMPLETED | TRAIN LOSS :: 0.09650205514411528| VAL LOSS :: 0.09772143835068058\n",
      "EPOCH 64 COMPLETED | TRAIN LOSS :: 0.0965195005004003| VAL LOSS :: 0.09769314431545235\n",
      "EPOCH 65 COMPLETED | TRAIN LOSS :: 0.09601616848478775| VAL LOSS :: 0.0972687333867094\n",
      "EPOCH 66 COMPLETED | TRAIN LOSS :: 0.09567649219375496| VAL LOSS :: 0.0969463556845476\n",
      "EPOCH 67 COMPLETED | TRAIN LOSS :: 0.09558530594475581| VAL LOSS :: 0.0968414865892714\n",
      "EPOCH 68 COMPLETED | TRAIN LOSS :: 0.09507909047237785| VAL LOSS :: 0.09631675060048038\n",
      "EPOCH 69 COMPLETED | TRAIN LOSS :: 0.09485024579663731| VAL LOSS :: 0.09609631004803842\n",
      "EPOCH 70 COMPLETED | TRAIN LOSS :: 0.09464959642714166| VAL LOSS :: 0.09588271236989596\n",
      "EPOCH 71 COMPLETED | TRAIN LOSS :: 0.09444000535428351| VAL LOSS :: 0.09564155224179346\n",
      "EPOCH 72 COMPLETED | TRAIN LOSS :: 0.09399922262810255| VAL LOSS :: 0.09525388831064853\n",
      "EPOCH 73 COMPLETED | TRAIN LOSS :: 0.09382662329863882| VAL LOSS :: 0.09507239571657326\n",
      "EPOCH 74 COMPLETED | TRAIN LOSS :: 0.0937485831164932| VAL LOSS :: 0.09498907706164932\n",
      "EPOCH 75 COMPLETED | TRAIN LOSS :: 0.09334327837269822| VAL LOSS :: 0.09458172017614094\n",
      "EPOCH 76 COMPLETED | TRAIN LOSS :: 0.09333130574459574| VAL LOSS :: 0.09455029763811044\n",
      "EPOCH 77 COMPLETED | TRAIN LOSS :: 0.09302324654723783| VAL LOSS :: 0.09426550100080062\n",
      "EPOCH 78 COMPLETED | TRAIN LOSS :: 0.09278941753402725| VAL LOSS :: 0.09400274119295435\n",
      "EPOCH 79 COMPLETED | TRAIN LOSS :: 0.09269134082265816| VAL LOSS :: 0.09391458486789427\n",
      "EPOCH 80 COMPLETED | TRAIN LOSS :: 0.0925227487489992| VAL LOSS :: 0.09377091513210567\n",
      "EPOCH 81 COMPLETED | TRAIN LOSS :: 0.09225388135508406| VAL LOSS :: 0.09348650700560446\n",
      "EPOCH 82 COMPLETED | TRAIN LOSS :: 0.09221283281625306| VAL LOSS :: 0.0934932524019215\n",
      "EPOCH 83 COMPLETED | TRAIN LOSS :: 0.09187745736589277| VAL LOSS :: 0.09311037750200164\n",
      "EPOCH 84 COMPLETED | TRAIN LOSS :: 0.09196268149519614| VAL LOSS :: 0.09320952882305848\n",
      "EPOCH 85 COMPLETED | TRAIN LOSS :: 0.09172821647317857| VAL LOSS :: 0.09296128242594072\n",
      "EPOCH 86 COMPLETED | TRAIN LOSS :: 0.09154271697357891| VAL LOSS :: 0.09281438811048841\n",
      "EPOCH 87 COMPLETED | TRAIN LOSS :: 0.09152893594875897| VAL LOSS :: 0.09279435148118494\n",
      "EPOCH 88 COMPLETED | TRAIN LOSS :: 0.09119810498398714| VAL LOSS :: 0.09244289871897514\n",
      "EPOCH 89 COMPLETED | TRAIN LOSS :: 0.09115241373098482| VAL LOSS :: 0.09240830224179344\n",
      "EPOCH 90 COMPLETED | TRAIN LOSS :: 0.09096559477582067| VAL LOSS :: 0.09218898578863093\n",
      "EPOCH 91 COMPLETED | TRAIN LOSS :: 0.09078038831064854| VAL LOSS :: 0.09202914151321058\n",
      "EPOCH 92 COMPLETED | TRAIN LOSS :: 0.09075072578062453| VAL LOSS :: 0.09198144655724581\n",
      "EPOCH 93 COMPLETED | TRAIN LOSS :: 0.09054802426941555| VAL LOSS :: 0.09180415592473977\n",
      "EPOCH 94 COMPLETED | TRAIN LOSS :: 0.09030940527421939| VAL LOSS :: 0.09155610628502803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 95 COMPLETED | TRAIN LOSS :: 0.09033134697758204| VAL LOSS :: 0.09154755464371499\n",
      "EPOCH 96 COMPLETED | TRAIN LOSS :: 0.08995927181745397| VAL LOSS :: 0.09118403162530025\n",
      "EPOCH 97 COMPLETED | TRAIN LOSS :: 0.0900339899419535| VAL LOSS :: 0.09127732005604487\n",
      "EPOCH 98 COMPLETED | TRAIN LOSS :: 0.08960151511208969| VAL LOSS :: 0.09084205784627698\n",
      "EPOCH 99 COMPLETED | TRAIN LOSS :: 0.0897850600980784| VAL LOSS :: 0.09105375160128104\n",
      "EPOCH 100 COMPLETED | TRAIN LOSS :: 0.08960166182946355| VAL LOSS :: 0.09087597237790236\n",
      "EPOCH 101 COMPLETED | TRAIN LOSS :: 0.08931070646517221| VAL LOSS :: 0.09055012610088072\n",
      "EPOCH 102 COMPLETED | TRAIN LOSS :: 0.08909730314251398| VAL LOSS :: 0.09034517694155327\n",
      "EPOCH 103 COMPLETED | TRAIN LOSS :: 0.0892821680844676| VAL LOSS :: 0.0905357584067254\n",
      "EPOCH 104 COMPLETED | TRAIN LOSS :: 0.08899678357686146| VAL LOSS :: 0.09028076941553242\n",
      "EPOCH 105 COMPLETED | TRAIN LOSS :: 0.08874345546437147| VAL LOSS :: 0.09000159107285827\n",
      "EPOCH 106 COMPLETED | TRAIN LOSS :: 0.08874687685148117| VAL LOSS :: 0.09000545096076862\n",
      "EPOCH 107 COMPLETED | TRAIN LOSS :: 0.0883698167033627| VAL LOSS :: 0.08964026741393116\n",
      "EPOCH 108 COMPLETED | TRAIN LOSS :: 0.08829632100680548| VAL LOSS :: 0.08956281224979985\n",
      "EPOCH 109 COMPLETED | TRAIN LOSS :: 0.08835755164131304| VAL LOSS :: 0.0896434435548439\n",
      "EPOCH 110 COMPLETED | TRAIN LOSS :: 0.08813325090072059| VAL LOSS :: 0.08942603262610088\n",
      "EPOCH 111 COMPLETED | TRAIN LOSS :: 0.08797687565052045| VAL LOSS :: 0.08930865332265812\n",
      "EPOCH 112 COMPLETED | TRAIN LOSS :: 0.08791896842473979| VAL LOSS :: 0.08919870276220974\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 500\n",
    "train_loss_liss = []\n",
    "val_loss_liss = []\n",
    "best_loss = float('inf')\n",
    "PATIENCE = 5\n",
    "loss_per=100\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    for batch_idx, batch in enumerate(train_data_loader):\n",
    "    \n",
    "        # Your training code here\n",
    "        batch = batch[0].to(device)  # Move data to the device if using GPU\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch)\n",
    "        \n",
    "        # TOTAL LOSS\n",
    "        recon_loss = criterion(outputs, batch)\n",
    "        regularization_loss = model.calculate_regularization_loss()\n",
    "        loss = recon_loss + regularization_loss\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "\n",
    "    # AT THE END OF EPOCH\n",
    "    val_loss = evaluate_model(model=model, loader=val_data_loader, criterion=criterion)\n",
    "    train_loss = evaluate_model(model=model, loader=train_data_loader, criterion=criterion)\n",
    "    \n",
    "    if epoch>0:\n",
    "        loss_per = ((old_loss-val_loss)/old_loss)*100\n",
    "    \n",
    "    if val_loss < best_loss:\n",
    "        \n",
    "        # SAVE BEST PARAMETERS\n",
    "        best_params = model.state_dict()\n",
    "        best_loss = val_loss\n",
    "        patience_counter=0\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        patience_counter +=1\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    old_loss = val_loss\n",
    "    \n",
    "    \n",
    "    val_loss_liss.append(val_loss)\n",
    "    train_loss_liss.append(train_loss)\n",
    "    \n",
    "    print(f\"EPOCH {epoch+1} COMPLETED | TRAIN LOSS :: {train_loss}| VAL LOSS :: {val_loss}\")\n",
    "    \n",
    "    if patience_counter >= PATIENCE: #or loss_per<.01:\n",
    "        print(f\"\\n\\n BREAKING AT EPOCH {epoch+1}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a73b13",
   "metadata": {},
   "source": [
    "# PLOT LOSSES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf60abb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have a list of x and y values\n",
    "x_values = np.array(range(len(train_loss_liss))) + 1\n",
    "y_values = np.array(train_loss_liss)\n",
    "\n",
    "\n",
    "# Create a scatter plot\n",
    "plt.scatter(x_values, y_values, label = 'TRAIN')\n",
    "plt.scatter(x_values, np.array(val_loss_liss), label = 'VAL')\n",
    "\n",
    "plt.grid()\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('MSE Loss')\n",
    "plt.title('Autoencoder Loss vs epochs')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8347a7",
   "metadata": {},
   "source": [
    "# SAVE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb481c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the entire model (including parameters, architecture, and optimizer state)\n",
    "torch.save(model, 'autoencoder_c_ventral.pth')\n",
    "torch.save(best_params, 'autoencoder_trained_params_c_ventral.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2960f4",
   "metadata": {},
   "source": [
    "# LOAD MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05e9bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the entire model\n",
    "model_c_ventral = torch.load('autoencoder_c_ventral.pth')\n",
    "\n",
    "# # If you saved only the model parameters\n",
    "# model = Autoencoder(1000, 59136)\n",
    "# model = Autoencoder(input_size, encoding_size)\n",
    "# model.load_state_dict(torch.load('autoencoder_model_params.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd63358",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_c_ventral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8281f89b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python-LDM",
   "language": "python",
   "name": "ldm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
